defaults:
  - model: wav2vec2
  - datasets:
    - common_voice_13_da
  - override hydra/job_logging: custom
  - _self_

dirs:
  data: data
  raw: raw
  processed: processed
  final: final
  models: models

seed: 4242

# Dataset parameters
characters_to_keep: 'abcdefghijklmnopqrstuvwxyzæøå0123456789éü '
max_seconds_per_example: 10
dataloader_num_workers: 8

# Can be `longest`, `max_length` or `do_not_pad`
# NOTE: This is automatically set to `max_length` in a multi-gpu setting
padding: longest

# This is a list of the sampling probability of each dataset, where null means that
# each dataset will be sampled equally often
dataset_probabilities:
  train: null
  val: null
  test: null

# Model parameters
pipeline_id: ${model.name}-finetuned
hub_id: alexandrainst/${pipeline_id}
model_dir: ${dirs.models}/${pipeline_id}
push_to_hub: false
fp16: true

# Training parameters
wandb: false
wandb_project: CoRal
wandb_group: default
wandb_name: null
resume_from_checkpoint: false
ignore_data_skip: false
save_total_limit: 2

# Optimisation parameters
learning_rate: 3e-5
adam_first_momentum: 0.9
adam_second_momentum: 0.98
total_batch_size: 256
per_device_batch_size: 64
max_steps: 120_000
warmup_steps: 10_000
logging_steps: 10
eval_steps: 100
save_steps: 100
early_stopping: false
early_stopping_patience: 50
