{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constsants\n",
    "\n",
    "VAL_FRAC = 0.002\n",
    "TEST_FRAC = 0.05\n",
    "\n",
    "GENDERS = [\"female\", \"male\"]\n",
    "\n",
    "\n",
    "DIALECTS = [\n",
    "    \"Bornholmsk\",\n",
    "    \"Fynsk\",\n",
    "    \"Københavnsk\",\n",
    "    \"Nordjysk\",\n",
    "    \"Sjællandsk\",\n",
    "    \"Sydømål\",\n",
    "    \"Sønderjysk\",\n",
    "    \"Vestjysk\",\n",
    "    \"Østjysk\",\n",
    "]\n",
    "\n",
    "\n",
    "age_group = namedtuple(\"age_group\", [\"min\", \"max\"])\n",
    "AGE_GROUPS = {\n",
    "    \"0-24\": age_group(0, 25),\n",
    "    \"25-49\": age_group(25, 50),\n",
    "    \"50-\": age_group(50, int(1e6)),\n",
    "}\n",
    "\n",
    "ACCENTS = [\"native\", \"foreign\"]\n",
    "\n",
    "# In the test set, we want to have samples that represent at least:\n",
    "# 40% of each gender (ignore nonbinary?)\n",
    "# 10% of each dialect\n",
    "# 20% of each age group\n",
    "# 5% with a foreign accent\n",
    "# Currently, the code only relies on the dialect criteria.\n",
    "# The code will add samples of each dialect until there are at least `DIALECT_CRITERA*100`% samples in\n",
    "# the dataset with that dialect.\n",
    "DIALECT_CRITERA = 0.08\n",
    "\n",
    "# Map Dialects as given in the huggingface coral dataset to the values in the dialect excel sheet column \"Underregionsprog\".\n",
    "# One note, in `Underregionsprog` we have `Amagermål`. Should we use `Københavnsk` instead?\n",
    "# Using `Københavnsk` for now.\n",
    "SUB_DIALECT_TO_DIALECT = {\n",
    "    \"Sydsjællandsk (sydligt sydsjællandsk)\": \"Sjællandsk\",\n",
    "    \"Vestjysk\": \"Vestjysk\",\n",
    "    \"Amagermål\": \"Københavnsk\",\n",
    "    \"Sjællandsk\": \"Sjællandsk\",\n",
    "    \"Fynsk\": \"Fynsk\",\n",
    "    \"Midtøstjysk\": \"Østjysk\",\n",
    "    \"Himmerlandsk\": \"Nordjysk\",\n",
    "    \"Østjysk\": \"Østjysk\",\n",
    "    \"Nørrejysk\": \"Nordjysk\",\n",
    "    \"Thybomål\": \"Nordjysk\",\n",
    "    \"Mellemslesvisk\": \"Sønderjysk\",\n",
    "    \"Sønderjysk\": \"Sønderjysk\",\n",
    "    \"Østligt sønderjysk (m. Als)\": \"Sønderjysk\",\n",
    "    \"Djurslandsk (Nord-, Syddjurs m. Nord- og Sydsamsø, Anholt)\": \"Østjysk\",\n",
    "    \"Sydvestjysk (m. Fanø)\": \"Vestjysk\",\n",
    "    \"Vendsysselsk (m. Hanherred og Læsø)\": \"Nordjysk\",\n",
    "    \"Nordfalstersk\": \"Sjællandsk\",\n",
    "    \"Nordsjællandsk\": \"Sjællandsk\",\n",
    "    \"Morsingmål\": \"Nordjysk\",\n",
    "    \"Sallingmål\": \"Vestjysk\",\n",
    "    \"Nordvestsjællandsk\": \"Sjællandsk\",\n",
    "    \"Sydøstjysk\": \"Østjysk\",\n",
    "    \"Vestlig sønderjysk (m. Mandø og Rømø)\": \"Sønderjysk\",\n",
    "    \"Sydømål\": \"Sydømål\",\n",
    "    \"Bornholmsk\": \"Bornholmsk\",\n",
    "    \"Ommersysselsk\": \"Østjysk\",\n",
    "    \"Lollandsk\": \"Sjællandsk\",\n",
    "    \"Vestfynsk (nordvest-, sydvestfynsk)\": \"Fynsk\",\n",
    "    \"Langelandsk\": \"Fynsk\",\n",
    "    \"Sydfynsk\": \"Fynsk\",\n",
    "    \"Sydvestsjællandsk\": \"Sjællandsk\",\n",
    "    \"Østsjællandsk\": \"Sjællandsk\",\n",
    "}\n",
    "assert set(SUB_DIALECT_TO_DIALECT.values()) == set(DIALECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def age_to_group(age: int) -> str:\n",
    "    \"\"\"Map age to age group.\n",
    "\n",
    "    Args:\n",
    "        age (int):\n",
    "            Age of the speaker.\n",
    "\n",
    "    Returns:\n",
    "        group (str):\n",
    "            Age group.\n",
    "    \"\"\"\n",
    "    for group, (min_age, max_age) in AGE_GROUPS.items():\n",
    "        if min_age <= age < max_age:\n",
    "            return group\n",
    "    raise ValueError(f\"Age {age} not in any group.\")\n",
    "\n",
    "\n",
    "def get_speakers(df: pd.DataFrame) -> list:\n",
    "    \"\"\"Get unique speakers.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame):\n",
    "            Dataframe with speakers.\n",
    "\n",
    "    Returns:\n",
    "        speakers (list):\n",
    "            List of unique speakers.\n",
    "    \"\"\"\n",
    "    speakers = df[\"id_speaker\"].unique().tolist()\n",
    "    return speakers\n",
    "\n",
    "\n",
    "def get_speaker_df(df: pd.DataFrame, dialect: str) -> pd.DataFrame:\n",
    "    \"\"\"Get dataframe with unique speakers for a dialect.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame):\n",
    "            Dataframe with speakers.\n",
    "        dialect (str):\n",
    "            Dialect to filter on.\n",
    "\n",
    "    Returns:\n",
    "        df_speaker (pd.DataFrame):\n",
    "            Dataframe with unique speakers for a dialect.\n",
    "    \"\"\"\n",
    "    df_dialect = df[df[\"dialect\"] == dialect]\n",
    "    df_speaker = df_dialect.drop_duplicates(subset=\"id_speaker\")\n",
    "    return df_speaker\n",
    "\n",
    "\n",
    "def get_probs(scores: list[float]) -> list[float]:\n",
    "    \"\"\"Get probabilities from scores.\n",
    "\n",
    "    Args:\n",
    "        scores (list[float]):\n",
    "            List of scores.\n",
    "\n",
    "    Returns:\n",
    "        list[float]:\n",
    "            List of probabilities.\n",
    "    \"\"\"\n",
    "    # use numpy\n",
    "    exp = np.exp(scores)\n",
    "    probs = exp / exp.sum()\n",
    "    return probs.tolist()\n",
    "\n",
    "\n",
    "def give_score(row: pd.Series, age_group_weights: dict, accent_weights: dict) -> float:\n",
    "    \"\"\"Score a row based on age group and accent.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series):\n",
    "            Row in the dataframe.\n",
    "        age_group_weights (dict):\n",
    "            Weights for age groups.\n",
    "        accent_weights (dict):\n",
    "            Weights for accents.\n",
    "\n",
    "    Returns:\n",
    "        score (float):\n",
    "            Score for the row.\n",
    "    \"\"\"\n",
    "    return age_group_weights[row[\"age_group\"]] + accent_weights[row[\"accent\"]]\n",
    "\n",
    "\n",
    "def random_sample(samples: list[str], seen: set[str], probs: list[float]) -> str:\n",
    "    \"\"\"Take a random weighted sample from a list of samples.\n",
    "\n",
    "    Args:\n",
    "        samples (list[str]):\n",
    "            List of samples.\n",
    "        seen (set[str]):\n",
    "            Set of seen samples.\n",
    "        probs (list[float]):\n",
    "            List of probabilities.\n",
    "\n",
    "    Returns:\n",
    "        sample (str):\n",
    "            Sample.\n",
    "    \"\"\"\n",
    "    assert set(samples) - seen != set(), \"No more samples to sample from\"\n",
    "\n",
    "    sample = np.random.choice(samples, p=probs)\n",
    "    while sample in seen:\n",
    "        sample = np.random.choice(samples, p=probs)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the coral dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"alexandrainst/coral\"\n",
    "coral = load_dataset(path=dataset_id, split=\"train\")\n",
    "\n",
    "# Remove audio column, as we will not be processing the audio data\n",
    "coral = coral.remove_columns(\"audio\")\n",
    "coral_length = len(coral)\n",
    "\n",
    "df = pd.DataFrame(coral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"].value_counts().plot(kind=\"bar\", title=\"Gender distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique nonbinary speakers\n",
    "df[df[\"gender\"] == \"nonbinary\"][\"id_speaker\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dialect\"] = df[\"dialect\"].map(SUB_DIALECT_TO_DIALECT)\n",
    "\n",
    "df[\"dialect\"].value_counts().plot(kind=\"bar\", title=\"Dialect distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speakers with the dialect \"Sydømål\"\n",
    "df[df[\"dialect\"] == \"Sydømål\"][\"id_speaker\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"accent\"] = df[\"language_native\"].apply(\n",
    "    lambda x: \"native\" if x == \"da\" else \"foreign\"\n",
    ")\n",
    "df[\"accent\"].value_counts().plot(kind=\"bar\", title=\"Native language distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map age to age group\n",
    "df[\"age_group\"] = df[\"age\"].apply(age_to_group)\n",
    "df[\"age_group\"].value_counts().plot(kind=\"bar\", title=\"Age group distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- Kun 1 speaker med dialekt \"Sydømål\".\n",
    "- Kun 2 speakers med \"nonbinary\" gender.\n",
    "\n",
    "Plan for at bygge test- og valideringsdatasæt:\n",
    "1. Inkluder samples med hensyn til \"Sydømål\" dialekt og \"nonbinary\" gender.\n",
    "2. Inkluder samples for hver dialekt, en dialekt af gangen.\n",
    "   1. Find alle speakers for det køn som er underrepræsenteret.\n",
    "   2. Lav sampling med vægtning baseret på aldersgruppe og accent (native/foreign)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_speakers = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Dataset class to keep track of the samples in the dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame):\n",
    "            Dataframe of the Coral dataset.\n",
    "\n",
    "    Attributes:\n",
    "        df (pd.DataFrame):\n",
    "            Dataframe of the Coral dataset.\n",
    "        frac (float):\n",
    "            Approximately this size of the dataset compared to the Coral dataset.\n",
    "        indices (list):\n",
    "            List of indices of the Coral dataset that will be included in the dataset.\n",
    "        self.gender_count (dict):\n",
    "            Keep track of the number of samples in the datasets for each gender.\n",
    "        self.dialect_count (dict):\n",
    "            Keep track of the number of samples in the datasets for each dialect.\n",
    "        self.age_group_count (dict):\n",
    "            Keep track of the number of samples in the datasets for each age group.\n",
    "        self.accent_count (dict):\n",
    "            Keep track of the number of samples in the datasets for each accent.\n",
    "        self.age_group_weights (dict):\n",
    "            Age group weights used to calculate the score of a sample.\n",
    "        self.accent_weights (dict):\n",
    "            Accent weights used to calculate the score of a sample.\n",
    "        self.betas (dict):\n",
    "            Shift the weights of the least represented feature.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, frac: float) -> None:\n",
    "        \"\"\"Initialize the Dataset class.\"\"\"\n",
    "        self.df = df\n",
    "        self.frac = frac\n",
    "        self.indices = []\n",
    "\n",
    "        # Initialize counts to 1 to avoid division by zero\n",
    "        self.gender_count = {gender: 1 for gender in GENDERS}\n",
    "        self.dialect_count = {dialect: 1 for dialect in DIALECTS}\n",
    "        self.age_group_count = {age_group: 1 for age_group in AGE_GROUPS.keys()}\n",
    "        self.accent_count = {accent: 1 for accent in ACCENTS}\n",
    "\n",
    "        self.age_group_weights = self._make_weights(count=self.age_group_count)\n",
    "        self.accent_weights = self._make_weights(count=self.accent_count)\n",
    "\n",
    "        self.betas = {\"age_group\": 5.0, \"accent\": 0.5}\n",
    "\n",
    "    def add_speaker_samples(self, speaker: str) -> None:\n",
    "        \"\"\"Add all samples of a speaker to the dataset.\n",
    "\n",
    "        Args:\n",
    "            speaker (str):\n",
    "                The id of the speaker\n",
    "        \"\"\"\n",
    "        speaker_samples = self.df[self.df[\"id_speaker\"] == speaker]\n",
    "        n_samples = len(speaker_samples)\n",
    "        indices = speaker_samples.index.tolist()\n",
    "        self.indices.extend(indices)\n",
    "\n",
    "        # Assuming that all samples of a speaker have the\n",
    "        # same gender, dialect, age_group, and native_language\n",
    "        row = speaker_samples.iloc[0]\n",
    "        gender = row[\"gender\"]\n",
    "        dialect = row[\"dialect\"]\n",
    "        age_group = age_to_group(age=row[\"age\"])\n",
    "        accent = row[\"accent\"]\n",
    "\n",
    "        # Don't count nonbinary\n",
    "        if gender != \"nonbinary\":\n",
    "            self.gender_count[gender] += n_samples\n",
    "        self.dialect_count[dialect] += n_samples\n",
    "        self.age_group_count[age_group] += n_samples\n",
    "        self.accent_count[accent] += n_samples\n",
    "\n",
    "        self._update_weights()\n",
    "\n",
    "    def _update_weights(self) -> None:\n",
    "        \"\"\"Update the weights of the age group and accent.\"\"\"\n",
    "        self.age_group_weights = self._make_weights(\n",
    "            count=self.age_group_count, beta=self.betas[\"age_group\"]\n",
    "        )\n",
    "        self.accent_weights = self._make_weights(\n",
    "            count=self.accent_count, beta=self.betas[\"accent\"]\n",
    "        )\n",
    "\n",
    "    def _make_weights(self, count: dict, beta: float = 5.0) -> dict:\n",
    "        \"\"\"Make weights based on counts.\n",
    "\n",
    "        Args:\n",
    "            count (dict):\n",
    "                Counts for a feature.\n",
    "            beta (float, optional):\n",
    "                Shift the weights of the least represented feature.\n",
    "\n",
    "        Returns:\n",
    "            weights (dict):\n",
    "                Weights for the feature.\n",
    "        \"\"\"\n",
    "        inv_count = {key: 1 / value for key, value in count.items()}\n",
    "        normalizer = sum(inv_count.values())\n",
    "        weights = {key: value / normalizer for key, value in inv_count.items()}\n",
    "\n",
    "        # Increase chance of sampling the least represented feature\n",
    "        max_key = max(weights, key=weights.get)\n",
    "        weights[max_key] += weights[max_key] * beta\n",
    "        return weights\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Representation of the Dataset class.\"\"\"\n",
    "        return f\"Gender count: {self.gender_count}\\nDialect count: {self.dialect_count}\\nAge group count: {self.age_group_count}\\nAccent count: {self.accent_count}\"\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Length of the dataset.\"\"\"\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(df=df, frac=TEST_FRAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilføj samples for nonbinary gender (kun to speakers, så tag en speaker til test og en til validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonbinary = df[df[\"gender\"] == \"nonbinary\"]\n",
    "speakers = get_speakers(df=df_nonbinary)\n",
    "speakers = list(set(speakers) - seen_speakers)\n",
    "\n",
    "speaker = random_sample(samples=speakers, seen=seen_speakers, probs=None)\n",
    "test_dataset.add_speaker_samples(speaker=speaker)\n",
    "seen_speakers.add(speaker)\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilføj samples for Sydømål (kun én speaker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydømål = df[df[\"dialect\"] == \"Sydømål\"]\n",
    "\n",
    "speakers = get_speakers(df=df_sydømål)\n",
    "speakers = list(set(speakers) - seen_speakers)\n",
    "\n",
    "speaker = speakers[0]\n",
    "test_dataset.add_speaker_samples(speaker=speaker)\n",
    "seen_speakers.add(speaker)\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilføj samples for de resterende dialekter, én af gangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples med dialekt `Sydømål` er allerede blevet tilføjet.\n",
    "dialects = list(set(DIALECTS) - set([\"Sydømål\"]))\n",
    "\n",
    "\n",
    "def get_dialect_samples(dataset: Dataset, dialects: list[str]):\n",
    "    \"\"\"Get samples of dialects each dialect such that the dataset has ~10% of each dialect.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset):\n",
    "            Dataset object (test or val).\n",
    "        dialects (list[str]):\n",
    "            List of dialects.\n",
    "\n",
    "    Returns:\n",
    "        dataset (Dataset):\n",
    "            Dataset object with samples of each dialect.\n",
    "    \"\"\"\n",
    "    n_samples_required = int(coral_length * dataset.frac * DIALECT_CRITERA)\n",
    "    for dialect in dialects:\n",
    "        while dataset.dialect_count[dialect] < n_samples_required:\n",
    "            df_speaker = get_speaker_df(df=df, dialect=dialect)\n",
    "\n",
    "            # Remove rows that have nonbinary gender\n",
    "            df_speaker = df_speaker[df_speaker[\"gender\"] != \"nonbinary\"]\n",
    "\n",
    "            # Remove speakers of the gender that is most frequent in test dataset.\n",
    "            most_frequent_gender = max(\n",
    "                dataset.gender_count, key=dataset.gender_count.get\n",
    "            )\n",
    "            df_speaker = df_speaker[df_speaker[\"gender\"] != most_frequent_gender]\n",
    "\n",
    "            assert len(df_speaker) > 0, \"No speakers left\"\n",
    "\n",
    "            df_speaker[\"score\"] = df_speaker.apply(\n",
    "                lambda x: give_score(\n",
    "                    row=x,\n",
    "                    age_group_weights=dataset.age_group_weights,\n",
    "                    accent_weights=dataset.accent_weights,\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "            speakers = df_speaker[\"id_speaker\"].tolist()\n",
    "            scores = df_speaker[\"score\"].tolist()\n",
    "            probs = get_probs(scores=scores)\n",
    "\n",
    "            speaker = random_sample(samples=speakers, seen=seen_speakers, probs=probs)\n",
    "            dataset.add_speaker_samples(speaker=speaker)\n",
    "            seen_speakers.add(speaker)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "test_dataset = get_dialect_samples(dataset=test_dataset, dialects=dialects)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(df=df, frac=VAL_FRAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilføj sidste nonbinary speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonbinary = df[df[\"gender\"] == \"nonbinary\"]\n",
    "speakers = get_speakers(df=df_nonbinary)\n",
    "speakers = list(set(speakers) - seen_speakers)\n",
    "\n",
    "speaker = random_sample(samples=speakers, seen=seen_speakers, probs=None)\n",
    "val_dataset.add_speaker_samples(speaker=speaker)\n",
    "seen_speakers.add(speaker)\n",
    "\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilføj dialekter (ingen speaker med Sydømål tilbage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_dialect_samples(dataset=val_dataset, dialects=dialects)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HF splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = test_dataset.indices\n",
    "val_indices = val_dataset.indices\n",
    "\n",
    "hf_test_dataset = coral.select(indices=test_indices)\n",
    "hf_val_dataset = coral.select(indices=val_indices)\n",
    "train_indices = list(set(range(len(coral))) - set(test_indices + val_indices))\n",
    "hf_train_dataset = coral.select(indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_indices) + len(val_indices) + len(test_indices) == len(coral)\n",
    "len(train_indices), len(val_indices), len(test_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
