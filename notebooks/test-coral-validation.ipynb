{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets, load_dataset\n",
    "from hydra import compose, initialize\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "initialize(config_path=\"../config\", version_base=None)\n",
    "config = compose(config_name=\"split_creation\")\n",
    "\n",
    "\n",
    "def play_sample(sample: dict):\n",
    "    \"\"\"Play the audio of a sample.\"\"\"\n",
    "    audio = sample[\"audio\"][\"array\"]\n",
    "    display(IPythonAudio(audio, rate=sample[\"audio\"][\"sampling_rate\"]))\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        coral = concatenate_datasets(\n",
    "            dsets=[\n",
    "                split\n",
    "                for split in load_dataset(\n",
    "                    \"alexandrainst/coral\", name=\"read_aloud\"\n",
    "                ).values()\n",
    "                if split is not None\n",
    "            ]\n",
    "        )\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Encountered error: {str(e)}. Retrying...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a sample\n",
    "\n",
    "coral[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Play some samples with the worst CER\n",
    "\n",
    "worst_samples = coral.sort(\"asr_cer\", reverse=True).select(range(100))\n",
    "for sample in worst_samples:\n",
    "    print(f\"CER: {sample['asr_cer']:.0%}\")\n",
    "    print(f\"Text: {sample['text']!r}\")\n",
    "    play_sample(sample)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_SPEAKER_IDS: list[str] = [\n",
    "    \"spe_55028d05581a88a8655fa1f74ddfb5a1\",\n",
    "    \"spe_2937b289da4c0a7b9877c56ecead4794\",\n",
    "    \"spe_4aa23a60464a18e3597cdeb3606ac572\",\n",
    "    \"spe_fbf3381f525dbe5ddf1a2a1d36e9c4b9\",\n",
    "    \"spe_deedf738efa054ae460989be3033a3cf\",\n",
    "    \"spe_d19f3558739cb61e2cc2d8be52c19141\",\n",
    "    \"spe_741ba3dd1acd26458718a591a980d743\",\n",
    "    \"spe_3fbe6022caf3c819597d4a28eafc092e\",\n",
    "    \"spe_d772d2cc8215cdcf3a962c7757156deb\",\n",
    "    \"spe_04be495fbbcf0187a0f17708b556ea13\",\n",
    "    \"spe_fa639f5932359117682753884585d883\",\n",
    "    \"spe_066938532ac270d527696f89d81f0de4\",\n",
    "    \"spe_c4ece6eb8bf41ab959af9e2f57a5aae6\",\n",
    "    \"spe_ab9690f6ac8dd2226f4bb14699444ed5\",\n",
    "    \"spe_71d9860fe866f922740368df660bd1d4\",\n",
    "    \"spe_290d17059a29fe3df395be2311c96fc1\",\n",
    "    \"spe_040c7192f1c56491f9b00c558ce87d83\",\n",
    "    \"spe_7b8398c898a828791c0fc40d6d146b3f\",\n",
    "    \"spe_6e7cb65603907f863e06d7a02e00fb67\",\n",
    "    \"spe_df3293886215084f5fd6a447bb379b11\",\n",
    "    \"spe_2f15ff95f96e7e173ffd77d5ce867858\",\n",
    "    \"spe_199e03b334b15576a69be73ea39a34d5\",\n",
    "    \"spe_dbf8b55bf5364a9d6eaed082697b36fc\",\n",
    "    \"spe_9f6f2d21463e94f5403f67754913fabc\",\n",
    "    \"spe_8948a0cc310c6fa8161665d4eda79846\",\n",
    "    \"spe_5e319f90767d47e11731d95e314e4670\",\n",
    "    \"spe_6e67cbe51a49d9e4abbd7699a4a89d91\",\n",
    "    \"spe_03e8b9d0ee8d3192e113ff62c61e4916\",\n",
    "    \"spe_fade5754bc6e205fcce917e85dd8def1\",\n",
    "    \"spe_de430b1197cf26cb5f4011656a728ee5\",\n",
    "    \"spe_65c05e58f399d854594d4716454a806b\",\n",
    "    \"spe_26b2833fc94cadba302aba2a631da193\",\n",
    "    \"spe_fa6a417205bd632f6832f42120d291ea\",\n",
    "    \"spe_01fc2b156c7fe429f1b72bd3be5ad3c3\",\n",
    "    \"spe_7d6e87835e35371cba677fffefb10fb1\",\n",
    "]\n",
    "VALIDATION_SET_SPEAKER_IDS: list[str] = [\n",
    "    \"spe_a55cdc8a6a4230777bbe421825db705a\",\n",
    "    \"spe_046c02b65af055859e0f0a1885b2cc5c\",\n",
    "    \"spe_2dd1aa67190b348710f31482d291418c\",\n",
    "    \"spe_8685f47cbde80df2b261c1dff5649f22\",\n",
    "    \"spe_dabbad0be26f953503dcf196440eb7a7\",\n",
    "    \"spe_3dd62e87b39a71dc50aaf90199dad34b\",\n",
    "    \"spe_51b02c4d372de72ba1cab851642ab363\",\n",
    "    \"spe_4b7ba1403d8540b3101c07b9c8a19474\",\n",
    "    \"spe_6aeb15b456086536f45918dbdfc63ec6\",\n",
    "    \"spe_af2f2d470c277174a74583322f89c8bd\",\n",
    "    \"spe_349834612439f09df8374bd3016ba57e\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = coral.filter(\n",
    "    lambda sample: sample[\"id_speaker\"] in TEST_SET_SPEAKER_IDS\n",
    "    and sample[\"asr_cer\"] < 0.6\n",
    "    and sample[\"validated\"] != \"rejected\"\n",
    "    and sample[\"validated\"] != \"maybe\",\n",
    "    num_proc=8,\n",
    ")\n",
    "val = coral.filter(\n",
    "    lambda sample: sample[\"id_speaker\"] in VALIDATION_SET_SPEAKER_IDS\n",
    "    and sample[\"asr_cer\"] < 0.6\n",
    "    and sample[\"validated\"] != \"rejected\"\n",
    "    and sample[\"validated\"] != \"maybe\",\n",
    "    num_proc=8,\n",
    ")\n",
    "train = coral.filter(\n",
    "    lambda sample: sample[\"id_speaker\"]\n",
    "    not in TEST_SET_SPEAKER_IDS + VALIDATION_SET_SPEAKER_IDS\n",
    "    and sample[\"asr_cer\"] < 0.6\n",
    "    and sample[\"validated\"] != \"rejected\",\n",
    "    num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coral = DatasetDict(dict(train=train, val=val, test=test))\n",
    "new_coral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGroup(NamedTuple):\n",
    "    \"\"\"Named tuple to represent an age group.\"\"\"\n",
    "\n",
    "    min: int\n",
    "    max: int | None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Return the string representation of the AgeGroup class.\"\"\"\n",
    "        if self.max is None:\n",
    "            return f\"{self.min}-\"\n",
    "        return f\"{self.min}-{self.max - 1}\"\n",
    "\n",
    "    def __contains__(self, age: object) -> bool:\n",
    "        \"\"\"Check if an age is in the age group.\n",
    "\n",
    "        Args:\n",
    "            age:\n",
    "                The age to check.\n",
    "\n",
    "        Returns:\n",
    "            Whether the age is in the age group.\n",
    "        \"\"\"\n",
    "        if not isinstance(age, int):\n",
    "            return False\n",
    "        return self.min <= age and (self.max is None or age < self.max)\n",
    "\n",
    "\n",
    "def age_to_group(age: int, age_groups: list[AgeGroup]) -> str:\n",
    "    \"\"\"Return the age group of a given age.\n",
    "\n",
    "    Args:\n",
    "        age:\n",
    "            The age of the speaker.\n",
    "        age_groups:\n",
    "            A list of the possible age groups.\n",
    "\n",
    "    Returns:\n",
    "        The age group of the speaker.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            If the age is not in any age group.\n",
    "    \"\"\"\n",
    "    for age_group in age_groups:\n",
    "        if age in age_group:\n",
    "            return str(age_group)\n",
    "    raise ValueError(f\"Age {age} not in any age group, out of {age_groups}.\")\n",
    "\n",
    "\n",
    "def print_stats(split: Dataset) -> None:\n",
    "    \"\"\"Print statistics about the dataset.\"\"\"\n",
    "    print(f\"Number of samples: {len(split):,}\")\n",
    "    print(f\"Sample rate: {split[0]['audio']['sampling_rate']:,}\")\n",
    "\n",
    "    hours = sum(\n",
    "        sample[\"audio\"][\"array\"].shape[0] / sample[\"audio\"][\"sampling_rate\"] / 60 / 60\n",
    "        for sample in tqdm(split, desc=\"Counting number of hours\")\n",
    "    )\n",
    "    print(f\"Number of hours: {hours:,}\")\n",
    "\n",
    "    df = split.remove_columns(\"audio\").to_pandas()\n",
    "\n",
    "    print(f\"Number of unique speakers: {df.id_speaker.nunique():,}\")\n",
    "    print(f\"Number of unique sentences: {df.id_sentence.nunique():,}\")\n",
    "    print()\n",
    "\n",
    "    print(df.gender.value_counts(normalize=True))\n",
    "    print()\n",
    "\n",
    "    df.dialect = df.dialect.map(config.sub_dialect_to_dialect)\n",
    "    df.country_birth = df.country_birth.map(lambda x: \"DK\" if x is None else x)\n",
    "    df.loc[df.country_birth != \"DK\", \"dialect\"] = \"Non-native\"\n",
    "    print(df.dialect.value_counts(normalize=True))\n",
    "    print()\n",
    "\n",
    "    df[\"age_group\"] = df.age.apply(\n",
    "        lambda age: age_to_group(\n",
    "            age=age,\n",
    "            age_groups=[\n",
    "                AgeGroup(min=min_age, max=max_age)\n",
    "                for min_age, max_age in config.age_groups\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    print(df.age_group.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.remove_columns(\"audio\").to_pandas().id_sentence.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        new_coral.push_to_hub(\n",
    "            \"alexandrainst/coral\",\n",
    "            \"read_aloud\",\n",
    "            commit_message=\"Update test/val tests to have better dialectal representation\",\n",
    "        )\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to push to hub ({str(e)}) - retrying...\")\n",
    "        sleep(10)\n",
    "new_coral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
